#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:{} arch:headline
#+options: author:t broken-links:mark c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: SMILE Lab Challenge
#+date: <2023-09-15 Fri>
#+author: Nasy
#+email: nasyxx@gmail.com
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 30.0.50 (Org mode 9.7-pre)
#+cite_export:


* Overview

A cell segmentation task.

It officially starts from 10/1 and ends at 11:59pm on 2023/1/11 in GMT-5.

* Datasets

We provide a training dataset with 37 images and a testing dataset with 14 images.  The shape of the image is 1000x1000.  The images are in the =im= folder.  The ground truth of the training dataset is in the =mask= folder.  The testing dataset does not have ground truth.

To load image, you can use the python pillow packages:

#+begin_src python
  from PIL import Image
  import numpy as np


  Image.open("path/to/image.png")

  # for gray mask
  np.where(Image.open("path/to/mask.png").convert("L") > 127, 1, 0).astype("float32")
#+end_src

* Evaluation

This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:

\[2 \times | X \cap Y | / (| X | + |y|)\]

Or you can use python to calculate it by:

#+begin_src python
  2 * np.sum(x * y) / (np.sum(x) + np.sum(y))
#+end_src

where \(X\) is the predicted set of pixels, and \(Y\) is the ground truth. The Dice coefficient is defined to be 1 when both \(X\) and \(Y\) are empty. The leaderboard score is the mean of the Dice coefficients for each image in the test set.

* Submission File

In order to reduce the submission file size, our metric uses run-length encoding on the pixel values. Instead of submitting an exhaustive list of indices for your segmentation, you will submit pairs of values that contain a start position and a run length. E.g. '1 3' implies starting at pixel 1 and running a total of 3 pixels (1,2,3).

The competition format requires a space delimited list of pairs. For example, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. The metric checks that the pairs are sorted, positive, and the decoded pixel values are not duplicated. The pixels are numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc.

The file should contain a header and have the following format:

#+begin_example
  img,pixels
  1,1 1 5 1
  2,1 1
  3,1 1
#+end_example

You can convert to this format using the following python code:

#+begin_src python
  def rle(arr: np.ndarray) -> str:
    """Run length encoding."""
    arr1d = np.asarray(arr).flatten()
    arr1d = np.pad(arr1d, (1, 1), mode="constant", constant_values=0)
    runs = np.where(arr1d[1:] != arr1d[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return " ".join(map(str, runs))
#+end_src

* Code related

The code entry point is ~src/train/train.py~.

** Requirements

+ PDM :: https://pdm.fming.dev/latest/

** Install dependencies

#+begin_src sh
  pdm install
#+end_src

To use the CUDA version:

#+begin_src sh
  pdm install -G cuda
#+end_src

** Run

To train the model, run

#+begin_src sh
  XLA_PYTHON_CLIENT_PREALLOCATE=false XLA_FLAGS='--xla_gpu_deterministic_ops=true' CUDA_VISIBLE_DEVICES=0 pdm run "python -m train.train --no-infer --no-predict"
#+end_src

To inference the model, run

#+begin_src sh
  XLA_PYTHON_CLIENT_PREALLOCATE=false XLA_FLAGS='--xla_gpu_deterministic_ops=true' CUDA_VISIBLE_DEVICES=0 pdm run "python -m train.train --no-train --no-predict"
#+end_src
